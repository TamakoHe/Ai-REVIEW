#set text(size: 15pt)
#import "@preview/cmarker:0.1.1"
#import "@preview/mitex:0.2.4": mitex
= Genetic Algorithm(遗传算法)
这种算法的思维来自于进化论\
一些基本概念:
- Population: individual(个体)的集合  
- Selection: 越好的个体被选择的可能性越大
- Crossover: 字染色体的产生
- Mutation: 染色体在随机一定条件下会随机变异
一般情况下,会把搜索集的个体进行编码,主要是二进制编码.然后从种群中选择个体, 进行交叉, 变异, 形成新的种群.直到达到停止条件.
#figure(caption: [遗传算法的流程])[#image("2024-12-24-09-45-18.png")]
== 编码
用于表示个体的一种数据结构, 最常见的编码方式是用二进制编码.
== 初始种群(initial population)
- Population size:种群里有多少个个体
- The initialization method: 如何得到初始种群的?
== Selection(选择)
类似于生物进化,依据适应性选择,更好的个体被选择的几率越大,由fitness function来计算适应度
#figure(caption: [选择的概率计算, 计算适应度占总和的比例])[#image("2024-12-24-09-58-58.png")]
这种计算方式就像抽奖转盘一样, 所以叫做轮盘赌选择(Roulette Wheel)\
具体如何用计算机实现?\
$G_n$代表个体n的适应度
$S_1=G_1$,$S_2=G_1+G_2$,$S_3=G_1+G_2+G_3$, 直接从0到S_3中取得一个随机数, 在$[0,S_1]$就选个体1, 在$[S_1,S_2]$选个体2,在$[S_2,S_3]$就选个体3.\
更多的个体能够被选择带mating pool(交配池), 负面的效果是减少了多样性(diversity).不断的选择只能找到初始种群中最好的个体,不能真正解决优化问题.
== Crossover
这种操作一般设计为和适应度无关, 一般分为:
- One-Point Crossover
#figure(caption: [单点交叉])[#image("2024-12-24-10-25-56.png")]
- K-Point Crossover
找到K个分割点(Crossover sites),然后交换其中的子串.
#figure(caption: [K=2])[#image("2024-12-24-10-26-34.png")]
$p_c$:交叉率, 在交配池中的一对染色体发生交叉的概率, 一般比较高(0.6-0.9)
- 父母:parents
- 子代:offspring
== Mutation
较低的变异概率$P_m approx 0.01~0.001$
== 停止条件
- 达到最大代数
- 得到了满足要求的解
- 种群收敛(整个种群（population）的个体变得越来越相似，最终可能集中在少数解（或单个解）附近的现象)
== 遗传算法的优点
- 通用的优化算法
- 种群中的候选解可以并行评估
- 遗传算法通过进化过程能够发现多样化的解,从而在全局搜索中避免局部最优问题
- 过程实现起来不难
== 遗传算法的缺点
- 它可能不会得到一个非常高质量的最优解
- 该算法有几个参数，这些参数的选择影响着解的质量
- 速度慢
== 常用编码方式
- Binary(二进制字符串)
- Real vector(实数向量, 适合处理连续优化问题)
- 排列向量(表示特定顺序的)
== 初始化
对于二进制编码,可以用0,1以各50%的概率随机生成.\
对于实数表示, 在可行区间内随机生成.\
尽量平均化, 解决最优的答案\
根据相关领域的特定知识
== 变异
- 变异操作要使得理论上所有在搜索集里的结果都有可能出现
- 变异的强度(变异后和变异前的差异)
- 变异后的结果必须是有效的(valid)
二进制:0-1交换\
实数变异可以用随机加上一个符合正态分布的偏置值的办法解决\
对于排列,可以随机交换两个.
== Crossover
本质上:自带要继承一部分父代的东西\
- 产生的子代要是有效的(valid)
- 最好对于具体问题设计算法
#figure(caption: [一种产生子代的方式])[#image("2024-12-24-15-24-23.png")]
#figure(caption: [一种从排列产生子代的方式])[#image("2024-12-24-15-26-19.png")]
== 选择
#figure(caption: [计算在交配池中某一父代的平均个数])[#image("2024-12-24-15-29-57.png")]
轮盘赌选择法的缺陷:
- 难以选择不好的个体, 交配池很快就被优秀个体占据了(对每个适应度加一个较大的值可以减少他们之间被选中概率的差异)
- 如何这些个体的适应性差不多, 难以体现选择性(对每个个体减一个值可以增大它们被选择概率的差异)
- 可以用适应度函数的值进行排序, 把排名直接作为计算概率的标准
- Tournament selection:随机选k个个体, 然后从这k个中选择最好的
== Replacement(新旧替代)
- 旧种群完全由新种群替代
- 部分替代, 子代和父代竞争, 更加优秀的替代原来的
#figure(caption: [从探索与开发方面理解])[#image("2024-12-24-15-47-09.png")]
= 有约束的优化Constrained Optimization
- feasible(可行), infeasible(不可行), 由约束条件决定
== 比较规则
+ 可行解一定比不可行的好
+ 可行的当中, 让目标函数最优化的更好
+ 不可行当中, 违背约束条件越小的越好
+ 多个约束条件可能有优先级的区别
== 如何处理约束条件
- 惩罚函数
比如:\
$ min f(x) $
$ g(x)<=c $
$ min f(x)+k * h(g(x),c) $
$ h(g(x),c)=max{0, g(x)-c} $
$k$是惩罚系数, 用于控制惩罚的强度
- 决定惩罚系数$k$
    - 首先决定容忍违反条件的程度$epsilon$
    - 估计目标函数的期望最优值$f_0$
    - 例如50倍的惩罚:$epsilon times k= 50 f_0$, $k=(50 f_0)/epsilon$
- 所有条件可以通过加负号的方式变成$<=$,最大化问题再目标上加一个符号就可以变成最小化问题
== 遗传算法解决多目标优化
- 目标是要生成的结果接近帕累托最优解
主要的多目标解决方案:\
#cmarker.render("这张图描述了 **MOEA（Multi-Objective Evolutionary Algorithm，多目标进化算法）** 的一些流行变种。MOEA 是一种解决多目标优化问题的算法框架，通过模拟进化过程在多个目标之间找到一个折中解（Pareto前沿）。以下是图中三种流行变种的介绍：

---

### 1. **MOEA/D (Decomposition-based MOEAs)**  
MOEA/D 是基于分解的多目标进化算法，其核心思想是：
- **分解问题**：将多目标优化问题（MOP）分解为若干个单目标子问题。
- **协同求解**：通过协同求解这些子问题来近似 Pareto 前沿。
- **优点**：适合具有较强结构性或目标间存在特定关系的问题，能够有效地并行化求解。

例如：
- 每个子问题可以用加权和、Tchebycheff 方法或目标的边界来定义，并在进化过程中相互协作，逐步逼近 Pareto 前沿。

---

### 2. **NSGA-II (Dominance-based MOEAs)**  
NSGA-II 是基于支配关系的多目标进化算法，是当前最经典和广泛使用的一种方法，其特点包括：
- **支配关系排序**：根据解的 Pareto 支配关系对解进行排序，分配不同的优先级。
  - 一个解支配另一个解意味着它在所有目标上都不差于后者，并且至少在一个目标上更优。
- **多样性维护**：通过计算解在目标空间中的距离（如拥挤度距离）来保持种群多样性，避免过早收敛。
- **优点**：易于实现，适用于各种多目标优化问题，尤其是没有明确目标关系的问题。

例如：
- NSGA-II 会选择在目标上既优越又分布均匀的解作为下一代种群。

---

### 3. **IBEA (Indicator-based MOEAs)**  
IBEA 是基于指标的多目标进化算法，其核心思想是：
- **质量评估指标**：通过引入指标（如超体积 hypervolume）来评估解的质量。
  - 超体积指标衡量的是解集所覆盖的目标空间大小。
- **迭代选择**：根据每个解对整体指标的贡献大小选择新种群。
- **优点**：适合对解集整体质量有更高要求的问题，尤其是能够灵活设计自定义的质量指标。

例如：
- 如果一个解对超体积的贡献很大，则优先保留；如果贡献小，则可能被淘汰。

---

### 总结：
1. **MOEA/D**：
   - 优势：适合分解问题，效率高，易并行。
   - 劣势：对目标函数形状和权重分布敏感。

2. **NSGA-II**：
   - 优势：简单、稳定、适用广泛。
   - 劣势：在高维目标（如超过 3 个目标）时性能下降。

3. **IBEA**：
   - 优势：灵活、能够优化自定义指标。
   - 劣势：计算复杂度高，尤其是在计算超体积时。

这三种方法是多目标优化中常用的算法变种，适用于不同类型的问题场景和优化目标。")

== MOEA
MOEA假定用户有多种可能的偏好，并根据这些偏好调整解决方案\
可以只使用较小的种群大小就获得不错的结果(相对于IBEA在小种群方面)\
分解的思想有助于得到最终解的更均匀的分布\
把多目标问题分解为一个个不同的目标, 变成多个单目标优化问题,\
处理每个目标的进程会相互合作.

分解目标问题,例如:
$ g(x)=lambda_1 f_1 (x)+lambda_2 f_2(x);lambda_1+lambda_2=1 $
将多个不同权值的目标相加，将多目标问题分解为多个不同的子问题.解决这些子问题的
结果的连线就是PF,任何在PF上的一个点是一个子问题的最优解(对应一个向量$bold(lambda)$的子问题)
#figure(caption: [可以用参考点$z$相关的表示])[#image("2024-12-24-18-52-27.png")]
如何使得不同子问题之间进行合作呢?把问题A的最优解和问题B(A的近邻,$bold(lambda)$相近), 在选择的部分也可以选择近邻的一些好结果, A得到了结果,
如果一些新结果更适合近邻, 近邻的一部分结果也要被A的好解替代.
= Combinatorial Optimization(组合优化)
在一个离散集合中寻找最优解,比如旅行商问题,与连续的实数优化问题有所不同.\
例如背包问题, 如果用GA算法, 如果其中一个解超过了背包所能够承载的最大重量, 
那么就把最糟糕(价值重量比低)的逐渐剔除,直到满足条件.当然也可以用加惩罚函数的办法解决
#figure(caption: [一种适合排列的Crossover方法])[#image("2024-12-24-19-43-41.png")]

